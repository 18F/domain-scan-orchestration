#!/usr/bin/env python

from . import utils
from .models import Domain, Endpoint
from publicsuffix import PublicSuffixList
from publicsuffix import fetch

import requests
import re
import base64
import json
import csv
import os
import logging
import pytablewriter
import sys
import codecs
import OpenSSL

try:
    from urllib import parse as urlparse  # Python 3
except ImportError:
    import urlparse  # Python 2

import sslyze
import sslyze.synchronous_scanner

# We're going to be making requests with certificate validation disabled.
requests.packages.urllib3.disable_warnings()

# whether/where to cache, set via --cache
WEB_CACHE = None

# Default, overrideable via --user-agent
USER_AGENT = "pshtt, https scanning"

# Defaults to 1 second, overrideable via --timeout
TIMEOUT = 1

# The fields we're collecting, will be keys in JSON and
# column headers in CSV.
HEADERS = [
    "Domain", "Base Domain", "Canonical URL", "Live", "Redirect", "Redirect To",
    "Valid HTTPS", "Defaults to HTTPS", "Downgrades HTTPS", "Strictly Forces HTTPS",
    "HTTPS Bad Chain", "HTTPS Bad Hostname", "HTTPS Expired Cert",
    "HTTPS Self Signed Cert",
    "HSTS", "HSTS Header", "HSTS Max Age", "HSTS Entire Domain",
    "HSTS Preload Ready", "HSTS Preload Pending", "HSTS Preloaded",
    "Base Domain HSTS Preloaded", "Domain Supports HTTPS",
    "Domain Enforces HTTPS", "Domain Uses Strong HSTS", "Unknown Error",
]

PRELOAD_CACHE = None
preload_list = None
preload_pending = None

# Used for determining base domain via Mozilla's public suffix list.
SUFFIX_CACHE = None
suffix_list = None

# Set if user wants to use a custom CA bundle
CA_FILE = None
STORE = "Mozilla"


def inspect(base_domain):
    domain = Domain(base_domain)
    domain.http = Endpoint("http", "root", base_domain)
    domain.httpwww = Endpoint("http", "www", base_domain)
    domain.https = Endpoint("https", "root", base_domain)
    domain.httpswww = Endpoint("https", "www", base_domain)

    # Analyze HTTP endpoint responsiveness and behavior.
    basic_check(domain.http)
    basic_check(domain.httpwww)
    basic_check(domain.https)
    basic_check(domain.httpswww)

    # Analyze HSTS header, if present, on each HTTPS endpoint.
    hsts_check(domain.https)
    hsts_check(domain.httpswww)

    return result_for(domain)


def result_for(domain):

    # print(utils.json_for(domain.to_object()))

    # Because it will inform many other judgments, first identify
    # an acceptable "canonical" URL for the domain.
    domain.canonical = canonical_endpoint(domain.http, domain.httpwww, domain.https, domain.httpswww)

    # First, the basic fields the CSV will use.
    result = {
        'Domain': domain.domain,
        'Base Domain': parent_domain_for(domain.domain),
        'Canonical URL': domain.canonical.url,
        'Live': is_live(domain),
        'Redirect': is_redirect(domain),
        'Redirect To': redirects_to(domain),

        'Valid HTTPS': is_valid_https(domain),
        'Defaults to HTTPS': is_defaults_to_https(domain),
        'Downgrades HTTPS': is_downgrades_https(domain),
        'Strictly Forces HTTPS': is_strictly_forces_https(domain),

        'HTTPS Bad Chain': is_bad_chain(domain),
        'HTTPS Bad Hostname': is_bad_hostname(domain),
        'HTTPS Expired Cert': is_expired_cert(domain),
        'HTTPS Self Signed Cert': is_self_signed_cert(domain),

        'HSTS': is_hsts(domain),
        'HSTS Header': hsts_header(domain),
        'HSTS Max Age': hsts_max_age(domain),
        'HSTS Entire Domain': is_hsts_entire_domain(domain),
        'HSTS Preload Ready': is_hsts_preload_ready(domain),
        'HSTS Preload Pending': is_hsts_preload_pending(domain),
        'HSTS Preloaded': is_hsts_preloaded(domain),
        'Base Domain HSTS Preloaded': is_parent_hsts_preloaded(domain),

        'Domain Supports HTTPS': is_domain_supports_https(domain),
        'Domain Enforces HTTPS': is_domain_enforces_https(domain),
        'Domain Uses Strong HSTS': is_domain_strong_hsts(domain),

        'Unknown Error': did_domain_error(domain),
    }

    # But also capture the extended data for those who want it.
    result['endpoints'] = domain.to_object()

    return result


def ping(url, allow_redirects=False, verify=True):
    # If there is a custom CA file and we want to verify
    # use that instead when pinging with requests

    # By changing the verify param from a boolean to a .pem file, the
    # requests module will use the .pem to validate HTTPS connections.
    if CA_FILE and verify:
        verify = CA_FILE

    return requests.get(
        url,

        allow_redirects=allow_redirects,

        # Validate certificates.
        verify=verify,

        # set by --user_agent
        headers={'User-Agent': USER_AGENT},

        # set by --timeout
        timeout=TIMEOUT
    )


def basic_check(endpoint):
    logging.debug("Pinging %s..." % endpoint.url)

    # Test the endpoint. At first:
    #
    # * Don't follow redirects. (Will only follow if necessary.)
    #   If it's a 3XX, we'll ping again to follow redirects. This is
    #   necessary to reliably scope any errors (e.g. TLS errors) to
    #   the original endpoint.
    #
    # * Validate certificates. (Will figure out error if necessary.)
    try:
        req = ping(endpoint.url)

        endpoint.live = True
        if endpoint.protocol == "https":
            endpoint.https_valid = True

    except requests.exceptions.SSLError as err:
        logging.warn("Error validating certificate.")
        logging.debug("{0}".format(err))

        # Retry with certificate validation disabled.
        try:
            req = ping(endpoint.url, verify=False)
        except requests.exceptions.SSLError as err:
            # If it's a protocol error or other, it's not live.
            endpoint.live = False
            logging.warn("Unexpected SSL protocol (or other) error during retry.")
            logging.debug("{0}".format(err))
            return
        except requests.exceptions.RequestException as err:
            endpoint.live = False
            logging.warn("Unexpected requests exception during retry.")
            logging.debug("{0}".format(err))
            return
        except OpenSSL.SSL.Error as err:
            endpoint.live = False
            logging.warn("Unexpected OpenSSL exception during retry.")
            logging.debug("{0}".format(err))
            return
        except Exception as err:
            endpoint.unknown_error = True
            logging.warn("Unexpected other unknown exception during requests retry.")
            logging.debug("{0}".format(err))
            return

        # If it was a certificate error of any kind, it's live.
        endpoint.live = True

        # Figure out the error(s).
        https_check(endpoint)

    except requests.exceptions.ConnectionError as err:
        endpoint.live = False
        logging.debug("{0}".format(err))
        return

    # And this is the parent of ConnectionError and other things.
    # For example, "too many redirects".
    # See https://github.com/kennethreitz/requests/blob/master/requests/exceptions.py
    except requests.exceptions.RequestException as err:
        endpoint.live = False
        logging.warn("Unexpected other requests exception.")
        logging.debug("{0}".format(err))
        return

    except Exception as err:
        endpoint.unknown_error = True
        logging.warn("Unexpected other unknown exception during initial request.")
        logging.debug("{0}".format(err))
        return

    # Endpoint is live, analyze the response.
    endpoint.headers = req.headers

    endpoint.status = req.status_code

    if (req.headers.get('Location') is not None) and str(endpoint.status).startswith('3'):
        endpoint.redirect = True

    if endpoint.redirect:
        try:
            location_header = req.headers.get('Location')
            # Absolute redirects (e.g. "https://example.com/Index.aspx")
            if location_header.startswith("http:") or location_header.startswith("https:"):
                immediate = location_header

            # Relative redirects (e.g. "Location: /Index.aspx").
            # Construct absolute URI, relative to original request.
            else:
                immediate = urlparse.urljoin(endpoint.url, location_header)

            # Chase down the ultimate destination, ignoring any certificate warnings.
            ultimate_req = None
        except Exception as err:
            endpoint.unknown_error = True
            logging.warn("Unexpected other unknown exception when handling Requests Header.")
            logging.debug("{0}".format(err))
            pass

        try:
            ultimate_req = ping(endpoint.url, allow_redirects=True, verify=False)
        except requests.exceptions.RequestException:
            # Swallow connection errors, but we won't be saving redirect info.
            pass
        except Exception as err:
            endpoint.unknown_error = True
            logging.warn("Unexpected other unknown exception when handling redirect.")
            logging.debug("{0}".format(err))
            return

        try:
            # Now establish whether the redirects were:
            # * internal (same exact hostname),
            # * within the zone (any subdomain within the parent domain)
            # * external (on some other parent domain)

            # The hostname of the endpoint (e.g. "www.agency.gov")
            subdomain_original = urlparse.urlparse(endpoint.url).hostname
            # The parent domain of the endpoint (e.g. "agency.gov")
            base_original = parent_domain_for(subdomain_original)

            # The hostname of the immediate redirect.
            # The parent domain of the immediate redirect.
            subdomain_immediate = urlparse.urlparse(immediate).hostname
            base_immediate = parent_domain_for(subdomain_immediate)

            endpoint.redirect_immediately_to = immediate
            endpoint.redirect_immediately_to_www = re.match(r'^https?://www\.', immediate)
            endpoint.redirect_immediately_to_https = immediate.startswith("https://")
            endpoint.redirect_immediately_to_http = immediate.startswith("http://")
            endpoint.redirect_immediately_to_external = (base_original != base_immediate)
            endpoint.redirect_immediately_to_subdomain = (
                (base_original == base_immediate) and
                (subdomain_original != subdomain_immediate)
            )

            if ultimate_req is not None:
                # For ultimate destination, use the URL we arrived at,
                # not Location header. Auto-resolves relative redirects.
                eventual = ultimate_req.url

                # The hostname of the eventual destination.
                # The parent domain of the eventual destination.
                subdomain_eventual = urlparse.urlparse(eventual).hostname
                base_eventual = parent_domain_for(subdomain_eventual)

                endpoint.redirect_eventually_to = eventual
                endpoint.redirect_eventually_to_https = eventual.startswith("https://")
                endpoint.redirect_eventually_to_http = eventual.startswith("http://")
                endpoint.redirect_eventually_to_external = (base_original != base_eventual)
                endpoint.redirect_eventually_to_subdomain = (
                    (base_original == base_eventual) and
                    (subdomain_original != subdomain_eventual)
                )

            # If we were able to make the first redirect, but not the ultimate redirect,
            # and if the immediate redirect is external, then it's accurate enough to
            # say that the eventual redirect is the immediate redirect, since you're capturing
            # the domain it's going to.
            # This also avoids "punishing" the domain for configuration issues of the site
            # it redirects to.
            elif endpoint.redirect_immediately_to_external:
                endpoint.redirect_eventually_to = endpoint.redirect_immediately_to
                endpoint.redirect_eventually_to_https = endpoint.redirect_immediately_to_https
                endpoint.redirect_eventually_to_http = endpoint.redirect_immediately_to_http
                endpoint.redirect_eventually_to_external = endpoint.redirect_immediately_to_external
                endpoint.redirect_eventually_to_subdomain = endpoint.redirect_immediately_to_subdomain
        except Exception as err:
            endpoint.unknown_error = True
            logging.warn("Unexpected other unknown exception when establishing redirects.")
            logging.debug("{0}".format(err))
            pass


# Given an endpoint and its detected headers, extract and parse
# any present HSTS header, decide what HSTS properties are there.
def hsts_check(endpoint):
    # Disqualify domains with a bad host, they won't work as valid HSTS.
    try:
        if endpoint.https_bad_hostname:
            endpoint.hsts = False
            return

        header = endpoint.headers.get("Strict-Transport-Security")

        if header is None:
            endpoint.hsts = False
            return

        endpoint.hsts = True
        endpoint.hsts_header = header

        # Set max age to the string after max-age
        # TODO: make this more resilient to pathological HSTS headers.

        # handle multiple HSTS headers, requests comma-separates them
        first_pass = re.split(',\s?', header)[0]
        second_pass = re.sub('\'', '', first_pass)

        temp = re.split(';\s?', second_pass)

        if "max-age" in header.lower():
            endpoint.hsts_max_age = int(temp[0][len("max-age="):])

        if endpoint.hsts_max_age <= 0:
            endpoint.hsts = False
            return

        # check if hsts includes sub domains
        if 'includesubdomains' in header.lower():
            endpoint.hsts_all_subdomains = True

        # Check is hsts has the preload flag
        if 'preload' in header.lower():
            endpoint.hsts_preload = True
    except Exception as err:
        endpoint.unknown_error = True
        logging.warn("Unknown exception when handling HSTS check.")
        logging.debug("{0}".format(err))
        return


# Uses sslyze to figure out the reason the endpoint wouldn't verify.
def https_check(endpoint):
    logging.debug("sslyzing %s..." % endpoint.url)

    # remove the https:// from prefix for sslyze
    try:
        hostname = endpoint.url[8:]
        server_info = sslyze.server_connectivity.ServerConnectivityInfo(hostname=hostname, port=443)
    except Exception as err:
        endpoint.unknown_error = True
        logging.warn("Unknown exception when checking server connectivity info with sslyze.")
        logging.debug("{0}".format(err))
        return

    try:
        server_info.test_connectivity_to_server()
    except sslyze.server_connectivity.ServerConnectivityError as err:
        logging.warn("Error in sslyze server connectivity check")
        logging.debug("{0}".format(err))
        return
    except Exception as err:
        endpoint.unknown_error = True
        logging.warn("Unknown exception in sslyze server connectivity check.")
        logging.debug("{0}".format(err))
        return

    try:
        command = sslyze.plugins.certificate_info_plugin.CertificateInfoScanCommand(ca_file=CA_FILE)
        scanner = sslyze.synchronous_scanner.SynchronousScanner()
        cert_plugin_result = scanner.run_scan_command(server_info, command)
    except Exception as err:
        endpoint.unknown_error = True
        logging.warn("Unknown exception in sslyze scanner.")
        logging.debug("{0}".format(err))
        return

    try:
        cert_response = cert_plugin_result.as_text()
    except AttributeError as err:
        logging.warn("Known error in sslyze 1.X with EC public keys. See https://github.com/nabla-c0d3/sslyze/issues/215")
        return None
    except Exception as err:
        endpoint.unknown_error = True
        logging.warn("Unknown exception in cert plugin.")
        logging.debug("{0}".format(err))
        return

    # Debugging
    # for msg in cert_response:
    #     print(msg)

    # Default endpoint assessments to False until proven True.
    endpoint.https_expired_cert = False
    endpoint.https_self_signed_cert = False
    endpoint.https_bad_chain = False
    endpoint.https_bad_hostname = False

    # STORE will be either "Mozilla" or "Custom"
    # depending on what the user chose.

    # A certificate can have multiple issues.
    for msg in cert_response:

        # Check for missing SAN.
        if (
            (("DNS Subject Alternative Names") in msg) and
            (("[]") in msg)
        ):
            endpoint.https_bad_hostname = True

        # Check for certificate expiration.
        if (
            (STORE in msg) and
            (("FAILED") in msg) and
            (("certificate has expired") in msg)
        ):
            endpoint.https_expired_cert = True

        # Check to see if the cert is self-signed
        if (
            (STORE in msg) and
            (("FAILED") in msg) and
            (("self signed certificate") in msg)
        ):
            endpoint.https_self_signed_cert = True

        # Check to see if there is a bad chain

        # NOTE: If this is the only flag that's set, it's probably
        # an incomplete chain
        # If this isnt the only flag that is set, it's might be
        # because there is another error. More debugging would
        # need to be done at this point, but not through sslyze
        # because sslyze doesn't have enough granularity

        if (
            (STORE in msg) and
            (("FAILED") in msg) and
            (("unable to get local issuer certificate") in msg)
        ):
            endpoint.https_bad_chain = True

        # Check for whether the hostname validates.
        if (
            (("Hostname Validation") in msg) and
            (("FAILED") in msg) and
            (("Certificate does NOT match") in msg)
        ):
            endpoint.https_bad_hostname = True


##
# Given behavior for the 4 endpoints, make a best guess
# as to which is the "canonical" site for the domain.
#
# Most of the domain-level decisions rely on this guess in some way.
##
def canonical_endpoint(http, httpwww, https, httpswww):

    # A domain is "canonically" at www if:
    #  * at least one of its www endpoints responds
    #  * both root endpoints are either down or redirect *somewhere*
    #  * either both root endpoints are down, *or* at least one
    #    root endpoint redirect should immediately go to
    #    an *internal* www endpoint
    # This is meant to affirm situations like:
    #   http:// -> https:// -> https://www
    #   https:// -> http:// -> https://www
    # and meant to avoid affirming situations like:
    #   http:// -> http://non-www,
    #   http://www -> http://non-www
    # or like:
    #   https:// -> 200, http:// -> http://www

    at_least_one_www_used = httpswww.live or httpwww.live

    def root_unused(endpoint):
        return (
            endpoint.redirect or
            (not endpoint.live) or
            endpoint.https_bad_hostname or  # harmless for http endpoints
            (not str(endpoint.status).startswith("2"))
        )

    def root_down(endpoint):
        return (
            (not endpoint.live) or
            endpoint.https_bad_hostname or
            (
                (not str(endpoint.status).startswith("2")) and
                (not str(endpoint.status).startswith("3"))
            )
        )

    def goes_to_www(endpoint):
        return (
            endpoint.redirect_immediately_to_www and
            (not endpoint.redirect_immediately_to_external)
        )

    all_roots_unused = root_unused(https) and root_unused(http)

    all_roots_down = root_down(https) and root_down(http)

    is_www = (
        at_least_one_www_used and
        all_roots_unused and (
            all_roots_down or
            goes_to_www(https) or
            goes_to_www(http)
        )
    )

    # A domain is "canonically" at https if:
    #  * at least one of its https endpoints is live and
    #    doesn't have an invalid hostname
    #  * both http endpoints are either down or redirect *somewhere*
    #  * at least one http endpoint redirects immediately to
    #    an *internal* https endpoint
    # This is meant to affirm situations like:
    #   http:// -> http://www -> https://
    #   https:// -> http:// -> https://www
    # and meant to avoid affirming situations like:
    #   http:// -> http://non-www
    #   http://www -> http://non-www
    # or:
    #   http:// -> 200, http://www -> https://www
    #
    # It allows a site to be canonically HTTPS if the cert has
    # a valid hostname but invalid chain issues.

    def https_used(endpoint):
        return endpoint.live and (not endpoint.https_bad_hostname)

    def http_unused(endpoint):
        return (
            endpoint.redirect or
            (not endpoint.live) or
            (not str(endpoint.status).startswith("2"))
        )

    def http_upgrades(endpoint):
        return (
            endpoint.redirect_immediately_to_https and
            (not endpoint.redirect_immediately_to_external)
        )

    at_least_one_https_endpoint = https_used(https) or https_used(httpswww)
    all_http_unused = http_unused(http) and http_unused(httpwww)
    both_http_down = (not http.live) and (not httpwww.live)
    at_least_one_http_upgrades = http_upgrades(http) or http_upgrades(httpwww)

    is_https = (
        at_least_one_https_endpoint and
        all_http_unused and
        (
            both_http_down or at_least_one_http_upgrades
        )
    )

    if is_www and is_https:
        return httpswww
    elif is_www and (not is_https):
        return httpwww
    elif (not is_www) and is_https:
        return https
    elif (not is_www) and (not is_https):
        return http


##
# Judgment calls based on observed endpoint data.
##


# Domain is "live" if *any* endpoint is live.
def is_live(domain):
    http, httpwww, https, httpswww = domain.http, domain.httpwww, domain.https, domain.httpswww

    return http.live or httpwww.live or https.live or httpswww.live


# Domain is "a redirect domain" if at least one endpoint is
# a redirect, and all endpoints are either redirects or down.
def is_redirect(domain):
    http, httpwww, https, httpswww = domain.http, domain.httpwww, domain.https, domain.httpswww

    # TODO: make sub-function of the conditional below.
    # def is_redirect_or_down(endpoint):

    return is_live(domain) and (
        (
            https.redirect_eventually_to_external or
            (not https.live) or
            https.https_bad_hostname or
            https.status >= 400
        ) and
        (
            httpswww.redirect_eventually_to_external or
            (not httpswww.live) or
            httpswww.https_bad_hostname or
            httpswww.status >= 400
        ) and
        (
            httpwww.redirect_eventually_to_external or
            (not httpwww.live) or
            httpwww.status >= 400
        ) and
        (
            http.redirect_eventually_to_external or
            (not http.live) or
            http.status >= 400
        ))


# If a domain is a "redirect domain", where does it redirect to?
def redirects_to(domain):
    canonical = domain.canonical

    if is_redirect(domain):
        return canonical.redirect_eventually_to
    else:
        return None


# A domain has "valid HTTPS" if it responds on port 443 at its canonical
# hostname with an unexpired valid certificate for the hostname.
def is_valid_https(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    # Evaluate the HTTPS version of the canonical hostname
    if canonical.host == "root":
        evaluate = https
    else:
        evaluate = httpswww

    return evaluate.live and evaluate.https_valid


# A domain "defaults to HTTPS" if its canonical endpoint uses HTTPS.
def is_defaults_to_https(domain):
    canonical = domain.canonical

    return (canonical.protocol == "https")


# Domain downgrades if HTTPS is supported in some way, but
# its canonical HTTPS endpoint immediately redirects internally to HTTP.
def is_downgrades_https(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    # The domain "supports" HTTPS if any HTTPS endpoint responds with
    # a certificate valid for its hostname.
    supports_https = (
        https.live and (not https.https_bad_hostname)
    ) or (
        httpswww.live and (not httpswww.https_bad_hostname)
    )

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    # Explicitly convert to bool to avoid unintentionally returning None,
    # which may happen if the site doesn't redirect.
    return bool(
        supports_https and
        canonical_https.redirect_immediately_to_http and
        (not canonical_https.redirect_immediately_to_external)
    )


# A domain "Strictly Forces HTTPS" if one of the HTTPS endpoints is
# "live", and if both *HTTP* endpoints are either:
#
#  * down, or
#  * redirect immediately to an HTTPS URI.
#
# This is different than whether a domain "Defaults" to HTTPS.
#
# * An HTTP redirect can go to HTTPS on another domain, as long
#   as it's immediate.
# * A domain with an invalid cert can still be enforcing HTTPS.
def is_strictly_forces_https(domain):
    http, httpwww, https, httpswww = domain.http, domain.httpwww, domain.https, domain.httpswww

    def down_or_redirects(endpoint):
        return ((not endpoint.live) or endpoint.redirect_immediately_to_https)

    https_somewhere = https.live or httpswww.live
    all_http_unused = down_or_redirects(http) and down_or_redirects(httpwww)

    return https_somewhere and all_http_unused


# Domain has a bad chain if either https endpoints contain a bad chain
def is_bad_chain(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    return canonical_https.https_bad_chain


# Domain has a bad hostname if either https endpoint fails hostname validation
def is_bad_hostname(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    return canonical_https.https_bad_hostname


# Returns if the either https endpoint has an expired cert
def is_expired_cert(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    return canonical_https.https_expired_cert


# Returns if the either https endpoint has a self-signed cert cert
def is_self_signed_cert(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    return canonical_https.https_self_signed_cert


# Domain has HSTS if its canonical HTTPS endpoint has HSTS.
def is_hsts(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    return canonical_https.hsts


# Domain's HSTS header is its canonical endpoint's header.
def hsts_header(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    return canonical_https.hsts_header


# Domain's HSTS max-age is its canonical endpoint's max-age.
def hsts_max_age(domain):
    canonical, https, httpswww = domain.canonical, domain.https, domain.httpswww

    if canonical.host == "www":
        canonical_https = httpswww
    else:
        canonical_https = https

    return canonical_https.hsts_max_age


# Whether a domain's ROOT endpoint includes all subdomains.
def is_hsts_entire_domain(domain):
    https = domain.https

    return https.hsts_all_subdomains


# Whether a domain's ROOT endpoint is preload-ready.
def is_hsts_preload_ready(domain):
    https = domain.https

    eighteen_weeks = ((https.hsts_max_age is not None) and (https.hsts_max_age >= 10886400))
    preload_ready = (eighteen_weeks and https.hsts_all_subdomains and https.hsts_preload)

    return preload_ready


# Whether a domain is formally pending inclusion
# in Chrome's HSTS preload list.
def is_hsts_preload_pending(domain):
    return domain.domain in preload_pending


# Whether a domain is contained in Chrome's HSTS preload list.
def is_hsts_preloaded(domain):
    return domain.domain in preload_list


# Whether a domain's parent domain is in Chrome's HSTS preload list.
def is_parent_hsts_preloaded(domain):
    return is_hsts_preloaded(Domain(parent_domain_for(domain.domain)))


# For "x.y.domain.gov", return "domain.gov".
def parent_domain_for(hostname):
    return suffix_list.get_public_suffix(hostname)


# A domain 'Supports HTTPS' when it doesn't downgrade and has valid HTTPS,
# or when it doesn't downgrade and has a bad chain but not a bad hostname.
# Domains with a bad chain "support" HTTPS but user-side errors should be expected.
def is_domain_supports_https(domain):
    return (
        (not is_downgrades_https(domain)) and
        is_valid_https(domain)
    ) or (
        (not is_downgrades_https(domain)) and
        is_bad_chain(domain) and
        (not is_bad_hostname(domain))
    )


# A domain that 'Enforces HTTPS' must 'Support HTTPS' and default to HTTPS.
# For websites (where Redirect is false) they are allowed to eventually
# redirect to an https:// URI. For "redirect domains" (domains where the
# Redirect value is true) they must immediately redirect clients to an
# https:// URI (even if that URI is on another domain) in order to be said to
# enforce HTTPS.
def is_domain_enforces_https(domain):
    return is_domain_supports_https(domain) and (
        is_strictly_forces_https(domain) and
        (
            is_defaults_to_https(domain) or
            is_redirect(domain)
        ) or (
            (not is_strictly_forces_https(domain)) and
            is_defaults_to_https(domain)
        )
    )


def is_domain_strong_hsts(domain):
    if is_hsts(domain) and hsts_max_age(domain):
        return (
            is_hsts(domain) and
            hsts_max_age(domain) >= 31536000
        )
    else:
        return None


# Checks if the domain had an Unknown error somewhere
# The main purpos of this is to flag any odd websites for
# further debugging with other tools.
def did_domain_error(domain):
    http, httpwww, https, httpswww = domain.http, domain.httpwww, domain.https, domain.httpswww

    return (
        http.unknown_error or httpwww.unknown_error or
        https.unknown_error or httpswww.unknown_error
    )


# Fetch the Chrome preload pending list. Don't cache, it's quick/small.
def fetch_preload_pending():
    logging.debug("Fetching Chrome pending preload list...")

    pending_url = "https://hstspreload.org/api/v2/pending"
    request = requests.get(pending_url)

    # TODO: abstract Py 2/3 check out to utils
    if sys.version_info[0] < 3:
        raw = request.content
    else:
        raw = str(request.content, 'utf-8')

    pending_json = json.loads(raw)

    pending = []
    for entry in pending_json:
        if entry.get('include_subdomains', False) is True:
            pending.append(entry['name'])

    return pending


def create_preload_list():
    preload_json = None

    if PRELOAD_CACHE and os.path.exists(PRELOAD_CACHE):
        logging.debug("Using cached Chrome preload list.")
        preload_json = json.loads(open(PRELOAD_CACHE).read())
    else:
        logging.debug("Fetching Chrome preload list from source...")

        # Downloads the chromium preloaded domain list and sets it to a global set
        file_url = 'https://chromium.googlesource.com/chromium/src/net/+/master/http/transport_security_state_static.json?format=TEXT'

        # TODO: proper try/except around this network request
        request = requests.get(file_url)
        raw = request.content

        # To avoid parsing the contents of the file out of the source tree viewer's
        # HTML, we download it as a raw file. googlesource.com Base64-encodes the
        # file to avoid potential content injection issues, so we need to decode it
        # before using it. https://code.google.com/p/gitiles/issues/detail?id=7
        raw = base64.b64decode(raw).decode('utf-8')

        # The .json file contains '//' comments, which are not actually valid JSON,
        # and confuse Python's JSON decoder. Begone, foul comments!
        raw = ''.join([re.sub(r'^\s*//.*$', '', line)
                       for line in raw.splitlines()])

        preload_json = json.loads(raw)

        if PRELOAD_CACHE:
            logging.debug("Caching preload list at %s" % PRELOAD_CACHE)
            utils.write(utils.json_for(preload_json), PRELOAD_CACHE)

    # For our purposes, we only care about entries that includeSubDomains
    fully_preloaded = []
    for entry in preload_json['entries']:
        if entry.get('include_subdomains', False) is True:
            fully_preloaded.append(entry['name'])

    return fully_preloaded


def load_suffix_list():
    if SUFFIX_CACHE and os.path.exists(SUFFIX_CACHE):
        logging.debug("Using cached suffix list.")
        cache_file = codecs.open(SUFFIX_CACHE, encoding='utf-8')
        suffixes = PublicSuffixList(cache_file)
    else:
        # File does not exist, download current list and cache it at given location.
        logging.debug("Downloading the Public Suffix List...")
        cache_file = fetch()
        content = cache_file.readlines()
        suffixes = PublicSuffixList(content)

        if SUFFIX_CACHE:
            logging.debug("Caching suffix list at %s" % SUFFIX_CACHE)
            utils.write(''.join(content), SUFFIX_CACHE)

    return suffixes


def md_for(results, out_fd):
    value_matrix = []
    for result in results:
        row = []
        # TODO: Fix this upstream
        for header in HEADERS:
            if (header != "HSTS Header") and (header != "HSTS Max Age") and (header != "Redirect To"):
                if result[header] is None:
                    result[header] = False
            row.append(" %s" % result[header])
        value_matrix.append(row)

    writer = pytablewriter.MarkdownTableWriter()
    writer.header_list = HEADERS
    writer.value_matrix = value_matrix

    writer.stream = out_fd
    writer.write_table()


# Output a CSV string for an array of results, with a
# header row, and with header fields in the desired order.
def csv_for(results, out_filename):
    out_file = open(out_filename, 'w')
    writer = csv.writer(out_file)

    writer.writerow(HEADERS)

    for result in results:
        row = []
        # TODO: Fix this upstream
        for header in HEADERS:
            if (header != "HSTS Header") and (header != "HSTS Max Age") and (header != "Redirect To"):
                if result[header] is None:
                    result[header] = False
            row.append(result[header])
        writer.writerow(row)

    out_file.close()


def inspect_domains(domains, options):
    # Override timeout, user agent, preload cache, default CA bundle
    global TIMEOUT, USER_AGENT, PRELOAD_CACHE, WEB_CACHE, SUFFIX_CACHE, CA_FILE, STORE

    if options.get('timeout'):
        TIMEOUT = int(options['timeout'])
    if options.get('user_agent'):
        USER_AGENT = options['user_agent']
    if options.get('preload_cache'):
        PRELOAD_CACHE = options['preload_cache']
    if options.get('cache'):
        # TODO: requests-cache has a blocking bug for us, now
        # that we're tweaking allow_redirects and verify parameters.
        # Caching disabled until bug is fixed, or routed around.
        #
        # https://github.com/reclosedev/requests-cache/issues/70
        #
        # cache_dir = ".cache"
        # utils.mkdir_p(cache_dir)
        # requests_cache.install_cache("%s/cache" % cache_dir)
        logging.warn("WARNING: Caching disabled.")
    if options.get('suffix_cache'):
        SUFFIX_CACHE = options['suffix_cache']
    if options.get('ca_file'):
        CA_FILE = options['ca_file']
        # By default, the store that we want to check is the Mozilla store
        # However, if a user wants to use their own CA bundle, check the
        # "Custom" Option from the sslyze output.
        STORE = "Custom"

    # Download HSTS preload list, caches locally.
    global preload_list
    preload_list = create_preload_list()

    # Download HSTS pending preload list. Not cached.
    global preload_pending
    preload_pending = fetch_preload_pending()

    global suffix_list
    suffix_list = load_suffix_list()

    # For every given domain, get inspect data.
    results = []
    for domain in domains:
        results.append(inspect(domain))

    return results
